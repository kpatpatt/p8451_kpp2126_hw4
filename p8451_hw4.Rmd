---
title: "p8451_hw4"
output: html_document
date: "2023-02-14"
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(caret)
library(stats)
```

## Part I: Implementing a Simple Prediction Pipeline

The New York City Department of Health administered a questionnaire on general health and physical activity among residents. Using the dataset class4_p1.csv, fit and evaluate two prediction models using linear regression. 

##### The aim of the models are to predict the number of days in a month an individual reported having good physical health (feature name: healthydays). 

A codebook is provided so you can look-up the meaning and values of each feature in the dataset. (Note the codebook lists information on features that are not included in your dataset).

Your analytic pipeline should include the following:

1. Perform basic data cleaning. Note which features are continuous, which are categorical and ensure they are being stored that way in your R dataset (That is, if categorical variables have been read-in as continuous variables, convert them to factors)
2. Partition data into training and testing (use a 70/30 split)
3. Fit two prediction  models using  different subsets of the features in the training data. Features can overlap in the two models, but the feature sets should not be exactly the same across models. Clearly state which features were used in the two models.
4. Apply both models within the test data and determine which model is the preferred prediction model using the appropriate evaluation metric(s). 
5. Describe one setting (in 1-2 sentences) where the implementation of your final model would be useful.

```{r}
df = read_csv("./data/class4_p1.csv") %>%
  janitor::clean_names() %>%
  select(-x1)

#check variable type
str(df)
```
# Notes
a. `chronic1,3,4` need to be changed to factors from doubles (numeric)
b. `bmi` = continuous (no change)
c. `tobacco1` needs to be changed to factor from double (numeric)
d. `alcohol1` needs to be changed to factor from double (numeric)
e. `gpaq8totmin` is continuous, coded as double (numeric)
f. `gpaq11days` continuous, coded as double
g. `habits5` = col_double() -> needs to be factor
h. `habits7` = col_double() -> needs to be factor
i. `agegroup` = col_double() -> needs to be factor
j. `dem3` = col_double() -> needs to be factor (binary)
k. `dem4` = col_double() -> needs to be factor
l. `dem8` = col_double() -> needs to be factor
m. `povertygroup` = col_double() -> needs to be factor
n. `healthydays` = col_double() continuous

```{r clean and tidy}
df_tidy = df %>%
  rename(hypertension = "chronic1",
         diabetes = "chronic3",
         asthma = "chronic4",
         smokegtr3 = "tobacco1",
         drinkgtr2 = "alcohol1",
         physicalactivity = "habits5",
         dietquality = "habits7",
         sex = "dem3",
         hisp_lat = "dem4",
         usa_born = "dem8") %>%
  labelled::set_value_labels(
    hypertension = c("Yes" = 1, "No"= 2),
    diabetes = c("Yes" = 1, "No" = 2),
    asthma = c("Yes" = 1, "No" = 2),
    smokegtr3 = c("Most days (or all days)" = 1, "Some days" = 2, "Never" = 3),
    drinkgtr2 = c("Most days (or all days)" = 1, "Some days" = 2, "Never" = 3),
    physicalactivity = c("Very active" = 1, "Somewhat active" = 2, "Not very active" = 3, "Not active at all" = 4),
    dietquality = c("Excellent" = 1, "Very Good" = 2, "Good" = 3, "Fair" = 4, "Poor" = 5),
    agegroup = c("18-24" = 1, "25-44" = 2, "45-64" = 3, "65+" = 4),
    sex = c("Male" = 1, "Female" = 2),
    hisp_lat = c("Yes" = 1, "No"= 2),
    usa_born = c("USA" = 1, "Outside USA"= 2),
    povertygroup = c("<100%" = 1, "100-199%" = 2, "200-399%e" = 3, "400-599%" = 4, "600%" = 5, "Don't Know" = 6)
    ) %>%
  mutate_if(labelled::is.labelled, labelled::to_factor) %>%
  drop_na() %>% #remove NAs
  distinct(.keep_all = TRUE) #keep all unique ids
```

```{r preprocessing}
#set up for corr
df_numeric = df_tidy %>% 
  select(where(is.numeric))

#check for high correlations
correlations<-cor(df_numeric, use="complete.obs") #none of concern largest .11

#check dist of healthydays
df_tidy %>%
  ggplot(aes(x=healthydays)) +
  geom_bar() #left skewed
```



```{r partition}
set.seed(123)

train.index <- createDataPartition(y = df_tidy$healthydays,
                                   p = 0.7,
                                   list = FALSE)

head(train.index)

df.train<-df_tidy[train.index,]
df.test<-df_tidy[-train.index,]
```
```{r lm model}
#lmodel 1: predictors: age, diabetes, asthma and BMI
model1 <- lm(healthydays ~ agegroup + diabetes + asthma + bmi, 
              data = df.train)
#lmodel 2: predictors: age, tobacco use, alcohol use and diet
model2 <- lm(healthydays ~ agegroup + smokegtr3 + drinkgtr2 + dietquality, 
              data = df.train)
```


```{r model}
summary(model1)
```

## Part II: Conducting an Unsupervised Analysis

Using the dataset from the Group assignment Part 3 (USArrests), identify clusters using hierarchical analysis. Use an agglomerative algorithm for hierarchical clustering. Use a Euclidian distance measure to construct your dissimilarity matrix.

Conduct a hierarchical clustering analysis. Be sure to specify the linkage method used. Within your analysis, make sure you do both of the following:
Determine the optimal number of clusters using a clear, data-driven strategy.
Describe the composition of each cluster in terms of the original input features
 

Pretend that the data are from 2020 and not 1973. Describe one research question that can be addressed using the newly identified clusters. Briefly comment on any scientific or ethical considerations one should review before using these clusters for your specific question. NOTE: The clusters can be used as an exposure, an outcome or a covariate.
```{r}
df2 = USArrests

set.seed(123)
 
```

